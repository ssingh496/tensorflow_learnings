{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook contains code to train a fully connected deep neural network on MNIST. The principal changes from the previous notebook are:\n",
    "\n",
    "We have switched from a linear classifier to a deep neural network.\n",
    "\n",
    "We have added code to visualize the graph and summary data in TensorBoard.\n",
    "\n",
    "We are using the AdamOptimizer instead of the vanilla GradientDescentOptimizer.\n",
    "\n",
    "We are using Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sees= tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGDIR = './graphs/tutorial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#import the mnist dataset\n",
    "# It will be downloaded to '/tmp/data' if you don't already have a local copy.\n",
    "\n",
    "mnist = input_data.read_data_sets('/tmp/data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, validation, test: 55000, 5000, 10000\n"
     ]
    }
   ],
   "source": [
    "print (\"Train, validation, test: %d, %d, %d\" %  (len(mnist.train.images), len(mnist.validation.images), len(mnist.test.images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons in each hidden layer\n",
    "HIDDEN1_SIZE = 500\n",
    "HIDDEN2_SIZE = 250\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_PIXELS = 28 * 28\n",
    "\n",
    "# experiment with the nubmer of training steps to \n",
    "# see the effect\n",
    "TRAIN_STEPS = 2000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# we're using a different learning rate than the previous\n",
    "# notebook, and a new optimizer\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"input\"):\n",
    "    #Define inputs\n",
    "    images = tf.placeholder(dtype=tf.float32, shape=[None, NUM_PIXELS], name= \"pixel\")\n",
    "    print(images.shape)\n",
    "    labels = tf.placeholder(dtype=tf.float32, shape=[None, NUM_CLASSES], name = \"label\")\n",
    "    print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_layer(input, sizeOut, name=\"fc\", activation = None):\n",
    "    with tf.name_scope(\"model\"):\n",
    "        sizeIn =int(input.shape[1])\n",
    "        print(sizeIn)\n",
    "        w = tf.Variable(tf.truncated_normal([sizeIn, sizeOut], stddev=0.1), name=\"weights\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[sizeOut]), name=\"bias\")\n",
    "        wx_plus_b = tf.matmul(input, w) + b\n",
    "        if activation:\n",
    "            return activation(wx_plus_b)\n",
    "        return wx_plus_b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "(?, 500)\n",
      "500\n",
      "250\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "fc1 = fully_connected_layer(images, HIDDEN1_SIZE, \"fc1\", activation=tf.nn.relu)\n",
    "print(fc1.shape)\n",
    "fc2 = fully_connected_layer(fc1, HIDDEN2_SIZE, \"fc2\", activation=tf.nn.relu)\n",
    "\n",
    "dropped = tf.nn.dropout(fc2, keep_prob=0.9)\n",
    "\n",
    "# Finally, we'll calculate logists. This will be\n",
    "# the input to our Softmax function. Notice we \n",
    "# don't apply an activation at this layer.\n",
    "# If you've commented out the dropout layer,\n",
    "# switch the input here to 'fc2'.\n",
    "y = fully_connected_layer(dropped, NUM_CLASSES, name=\"output\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define loss and an optimizer\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=labels))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    # Whereas in the previous notebook we used a vanilla GradientDescentOptimizer\n",
    "    # here, we're using Adam. This is a single line of code change, and more\n",
    "    # importantly, TensorFlow will still automatically analyze our graph\n",
    "    # and determine how to adjust the variables to decrease the loss.\n",
    "    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables after the model is defined\n",
    "sees.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for i in range(TRAIN_STEPS):\n",
    "    batch_images, batch_labels = mnist.train.next_batch(BATCH_SIZE)\n",
    "    sees.run(train_step, feed_dict={images: batch_images, labels: batch_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.976000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model\n",
    "with tf.name_scope(\"calculate\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "                                  \n",
    "print(\"Accuracy %f\" % sees.run(accuracy, feed_dict={images: mnist.test.images, \n",
    "                                                    labels: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 3, actual: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19e877174e0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab\n",
    "\n",
    "prediction = tf.argmax(y,1)\n",
    "\n",
    "def predict(i):\n",
    "    image = mnist.test.images[i]\n",
    "    actual_label = np.argmax(mnist.test.labels[i])\n",
    "    predicted_label = sees.run(prediction, feed_dict={images: [image]})\n",
    "    return predicted_label, actual_label\n",
    "\n",
    "i = 200\n",
    "predicted, actual = predict(i)\n",
    "print (\"Predicted: %d, actual: %d\" % (predicted, actual))\n",
    "pylab.imshow(mnist.test.images[i].reshape((28,28)), cmap=pylab.cm.gray_r)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
